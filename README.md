# ğŸ“„ PDF Question Answering Bot

An interactive QnA chatbot that allows users to upload PDF documents, parse content, and query the text using Google Gemini Pro via a conversational interface built with Streamlit.

---

## ğŸš€ Features

- ğŸ“„ Upload and parse PDF files.
- ğŸ” Intelligent chunking for improved question matching.
- ğŸ“š Vector-based semantic search using ChromaDB.
- ğŸ¤– LLM-powered QnA system using `google-genai`.
- ğŸ–¥ï¸ Streamlit-based intuitive frontend.

---

## ğŸ—‚ï¸ Project Structure

```
PDF-QnA-Bot/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ chunker.py           # Splits PDF content into manageable chunks
â”‚   â”œâ”€â”€ gemini_llm.py        # Sends user query + context to Gemini LLM
â”‚   â”œâ”€â”€ pdf_parser.py        # Extracts text from PDF using PyPDF2
â”‚   â””â”€â”€ vector_store.py      # Embeds and stores text chunks using ChromaDB
â”œâ”€â”€ data/
â”‚   â””â”€â”€ uploaded_pdfs/       # Stores user-uploaded PDFs
â”œâ”€â”€ pages/
â”‚   â””â”€â”€ chat_page.py         # Streamlit page for chat interaction
â”œâ”€â”€ main.py                  # Streamlit app entry point
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # This file
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/PDF-QnA-Bot.git
cd PDF-QnA-Bot
```

### 2. Set up a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate  # Mac/Linux
.venv\Scripts\activate     # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

> If using Google Colab or Jupyter:
>
> ```python
> !pip install -q -U google-genai
> ```

---

## ğŸ” Environment Variables

Create a `.env` file in the project root and add your Gemini API key:

```env
GOOGLE_API_KEY=your_google_genai_key_here
```

---

## ğŸ§  How It Works

1. **Upload** a PDF â†’ Stored in `data/uploaded_pdfs/`.
2. **Extract** the text using `pdf_parser.py`.
3. **Chunk** the text using `chunker.py` for better semantic relevance.
4. **Embed** and **store** using `vector_store.py` + ChromaDB.
5. **Query** using `gemini_llm.py` with context retrieved by similarity search.
6. **Chat** with results shown via the `chat_page.py` interface in Streamlit.

---

## ğŸ§© Tech Stack

- **Frontend:** Streamlit
- **PDF Parsing:** PyPDF2
- **Vector DB:** ChromaDB
- **LLM:** Google Gemini via `google-genai`
- **Env Management:** python-dotenv

---

## âœ… To Run

```bash
streamlit run main.py
```

---

## ğŸ’¡ Future Additions

- Multi-document knowledge querying
- Chat history and memory
- Export chat transcripts
- Speech-based query input

---

## ğŸ“œ License

MIT License Â© 2025 Surya Suhas Reddy Sathi
